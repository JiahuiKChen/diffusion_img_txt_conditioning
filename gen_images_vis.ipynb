{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b061864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED THIS TO SAVE TO BIGGER DRIVE\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/datastor1/jiahuikchen/hf_cache'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from diffusers import StableUnCLIPImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d706ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910b61f33c024729a5ee536e9e4f0ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cutmix/mixup\n",
    "cutmix = v2.CutMix(num_classes=1)\n",
    "mixup = v2.MixUp(num_classes=1)\n",
    "preprocess = v2.Compose([\n",
    "    v2.PILToTensor(), \n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "img_txt_pipe = StableUnCLIPImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-1-unclip\", torch_dtype=torch.float16, \n",
    ")\n",
    "img_txt_pipe = img_txt_pipe.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10b5bd",
   "metadata": {},
   "source": [
    "### Implementation from [`diffusers/image_gen/gen_images.py`](https://github.com/JiahuiKChen/diffusers/blob/main/image_gen/gen_images.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9fe85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A40 \n",
    "PROMPT_FILE = \"/datastor1/jiahuikchen/diffusers/image_gen/imagenet_lt_balance_counts.txt\"\n",
    "TRAIN_DATA_TXT = \"/datastor1/jiahuikchen/diffusers/image_gen/ImageNet_LT_train.txt\"\n",
    "TRAIN_DATA_ROOT = \"/datastor1/imagenet2012_manual\"\n",
    "# OUTPUT_DIR = \"/datastor1/jiahuikchen/dropout\"\n",
    "\n",
    "# read in long-tail training data file, \n",
    "# construct dict: {int class label: <list of image paths>}\n",
    "# used to get training data images to condition generative model on\n",
    "TRAIN_DICT = {}\n",
    "with open(TRAIN_DATA_TXT) as train_file:\n",
    "    for line in train_file:\n",
    "        info = line.split() \n",
    "        class_label = int(info[1])\n",
    "        img_path = info[0]\n",
    "\n",
    "        if class_label in TRAIN_DICT:\n",
    "            TRAIN_DICT[class_label].append(img_path)\n",
    "        else:\n",
    "            TRAIN_DICT[class_label] = [img_path]\n",
    "\n",
    "            \n",
    "############################################################ METHODS\n",
    "# randomly select one image of given class \n",
    "def get_rand_img(class_label):\n",
    "    train_imgs = TRAIN_DICT[class_label]\n",
    "    img_path = random.choice(train_imgs)\n",
    "    img = load_image(os.path.join(TRAIN_DATA_ROOT, img_path))\n",
    "    return img\n",
    "\n",
    "# randomly select 2 images from given class,\n",
    "# perform cutmix on them and return the cutmixed image\n",
    "def cutmix_or_mixup(class_label, use_cutmix=True, use_mixup=False):\n",
    "    img_1 = preprocess(get_rand_img(class_label))\n",
    "    img_2 = preprocess(get_rand_img(class_label))\n",
    "    dummy_images = torch.stack((img_1, img_2))\n",
    "    dummy_labels = torch.zeros(size=(2,)).to(torch.int64)\n",
    "    cond_img = None\n",
    "    if use_cutmix:\n",
    "        cutmixed_img, _ = cutmix(dummy_images, dummy_labels)\n",
    "        cond_img = cutmixed_img[0]\n",
    "    elif use_mixup:\n",
    "        mixuped_img, _ = mixup(dummy_images, dummy_labels)\n",
    "        cond_img = mixuped_img[0]\n",
    "    return v2.functional.to_pil_image(cond_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c12a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to just sample 1 prompt and training image\n",
    "# and apply ALL conditionings\n",
    "# and visualize ALL condition's generations \n",
    "def gen_imgs(label=None, dropout=True, use_cutmix=True, use_mixup=True):\n",
    "    \n",
    "    # if given a label, find its txt prompt + randomly select training image\n",
    "    # do and show ALL conditioning images w/ each method\n",
    "    # show generation\n",
    "    \n",
    "    \n",
    "    # for each class, generate synthetic images with text label as prompt and randomly selected class image \n",
    "    with open(PROMPT_FILE) as gen_file:\n",
    "        # each line of this file contains the label (text label is the prompt) and how many images need to be generated\n",
    "        lines = [line.rstrip('\\n') for line in gen_file]\n",
    "\n",
    "    for line in lines:\n",
    "        l = line.split(\"\\\"\")\n",
    "        int_label = int(l[0].strip()); txt_label = l[1].strip(\"\\\"\"); gen_count = int(l[2].strip())\n",
    "\n",
    "        wandb.log({\"label\": int_label})\n",
    "\n",
    "        # create dict to pass into distributed inference of {prompts: [], cond_imgs: []}\n",
    "        total_prompts = [txt_label] * gen_count\n",
    "        all_indices = [i for i in range(gen_count)]\n",
    "        # image conditioning based on what's specified\n",
    "        if use_cutmix:\n",
    "            all_cond_imgs = [cutmix_or_mixup(int_label, use_cutmix=True, use_mixup=False) for i in range(gen_count)]\n",
    "        elif use_mixup:\n",
    "            all_cond_imgs = [cutmix_or_mixup(int_label, use_cutmix=False, use_mixup=True) for i in range(gen_count)]\n",
    "        else:\n",
    "            # randomly selecting an image from the same training class to generate conditioning image\n",
    "            all_cond_imgs = [get_rand_img(int_label) for i in range(gen_count)]\n",
    "        prompt_img_dict = {\"prompts\": total_prompts, \"cond_imgs\": all_cond_imgs, \"indices\": all_indices}\n",
    "        \n",
    "        with distributed_state.split_between_processes(prompt_img_dict) as prompt_imgs:\n",
    "            # within each process, get all the prompts, images to condition on, and indices -- then generate image\n",
    "            prompts = prompt_imgs[\"prompts\"]; cond_imgs = prompt_imgs[\"cond_imgs\"]; indices = prompt_imgs[\"indices\"] \n",
    "            for i in range(len(prompts)):\n",
    "                print(f\"Generating image {indices[i]} of {int_label}: \\\"{prompts[i]}\\\"\")\n",
    "                gen_image = img_txt_pipe(cond_imgs[i], prompts[i], dropout=dropout).images[0] \n",
    "                gen_img_name = f\"{int_label}_{indices[i]}.jpg\"\n",
    "                gen_image.save(os.path.join(OUTPUT_DIR, gen_img_name))\n",
    "\n",
    "# Gen images conditioned on 1 randomly selected image with the same class \n",
    "# gen_imgs(dropout=False, use_cutmix=False, use_mixup=False)\n",
    "\n",
    "# Gen images conditioned on mixup-ed random pairs with the same class \n",
    "# gen_imgs(dropout=False, use_cutmix=False, use_mixup=True)\n",
    "                \n",
    "# Gen images conditioned on cutmix-ed random paris with same class\n",
    "# gen_imgs(dropout=False, use_cutmix=True, use_mixup=False)\n",
    "                \n",
    "# Gen images conditioned on randomly selected images with same class, with dropout applied\n",
    "# gen_imgs(dropout=True, use_cutmix=False, use_mixup=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
